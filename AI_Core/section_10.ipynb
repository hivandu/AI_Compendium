{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 10, Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "dataset = fetch_openml(name='boston', version=1, as_frame=True, return_X_y=False, parser='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = dataset['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_then_most = np.percentile(dataframe['price'], 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "expensive = dataframe['expensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "    w = np.random.random_sample((1, 2))\n",
    "    b = 0\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    history_k_b_loss = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            index = random.choice(range(len(rm)))\n",
    "\n",
    "            x = np.array([rm[index], lstat[index]])\n",
    "            y = expensive[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            w = w + -1 * partial_w(x, y, yhat) * learning_rate\n",
    "            b = b + -1 * partial_b(x, y, yhat) * learning_rate\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "            history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        #     if batch % 100 == 0:\n",
    "        #         print('Epoch: {}, Batch: {}, loss:{}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "    return model_to_be_train, w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle write finished\n"
     ]
    }
   ],
   "source": [
    "model, w, b, losses = train(model, target, loss, partial_w, partial_b)\n",
    "\n",
    "with open('logistic_regression.model', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('w.model', 'wb') as f:\n",
    "    pickle.dump(w, f)\n",
    "\n",
    "with open('b.model', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "\n",
    "print('pickle write finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle read finished\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('logistic_regression.model', 'rb') as f:\n",
    "    model_r = pickle.load(f)\n",
    "\n",
    "with open('w.model', 'rb') as f:\n",
    "    w_r = pickle.load(f)\n",
    "\n",
    "with open('b.model', 'rb') as f:\n",
    "    b_r = pickle.load(f)\n",
    "\n",
    "print('pickle read finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predicated_labels, loss_labels = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM:6.121, LSTAT:8.44, EXPENSIVE:0, Predicated:0, loss_labels [0.45837434]\n",
      "RM:5.613, LSTAT:27.26, EXPENSIVE:0, Predicated:0, loss_labels [0.00124604]\n",
      "RM:7.014, LSTAT:14.79, EXPENSIVE:1, Predicated:0, loss_labels [0.13064883]\n",
      "RM:6.31, LSTAT:6.75, EXPENSIVE:0, Predicated:1, loss_labels [0.61823611]\n",
      "RM:6.619, LSTAT:7.22, EXPENSIVE:1, Predicated:1, loss_labels [0.61342378]\n",
      "RM:6.461, LSTAT:18.05, EXPENSIVE:0, Predicated:0, loss_labels [0.03803319]\n",
      "RM:5.454, LSTAT:18.06, EXPENSIVE:0, Predicated:0, loss_labels [0.02460551]\n",
      "RM:6.254, LSTAT:10.45, EXPENSIVE:0, Predicated:0, loss_labels [0.31426398]\n",
      "RM:5.52, LSTAT:24.56, EXPENSIVE:0, Predicated:0, loss_labels [0.00294508]\n",
      "RM:6.193, LSTAT:15.17, EXPENSIVE:0, Predicated:0, loss_labels [0.08424984]\n",
      "RM:6.137, LSTAT:13.44, EXPENSIVE:0, Predicated:0, loss_labels [0.13798434]\n",
      "RM:5.349, LSTAT:19.77, EXPENSIVE:0, Predicated:0, loss_labels [0.01340921]\n",
      "RM:6.43, LSTAT:5.21, EXPENSIVE:1, Predicated:1, loss_labels [0.74083149]\n",
      "RM:5.57, LSTAT:21.02, EXPENSIVE:0, Predicated:0, loss_labels [0.00977103]\n",
      "RM:6.739, LSTAT:4.69, EXPENSIVE:1, Predicated:1, loss_labels [0.79593437]\n",
      "RM:8.398, LSTAT:5.91, EXPENSIVE:1, Predicated:1, loss_labels [0.84393556]\n",
      "RM:6.459, LSTAT:23.98, EXPENSIVE:0, Predicated:0, loss_labels [0.00540618]\n",
      "RM:6.129, LSTAT:15.12, EXPENSIVE:0, Predicated:0, loss_labels [0.08335745]\n",
      "RM:6.77, LSTAT:4.84, EXPENSIVE:1, Predicated:1, loss_labels [0.78995185]\n",
      "RM:4.926, LSTAT:29.53, EXPENSIVE:0, Predicated:0, loss_labels [0.00043053]\n",
      "RM:5.786, LSTAT:14.15, EXPENSIVE:0, Predicated:0, loss_labels [0.09752219]\n",
      "RM:6.169, LSTAT:5.81, EXPENSIVE:1, Predicated:1, loss_labels [0.67568607]\n",
      "RM:3.863, LSTAT:13.33, EXPENSIVE:0, Predicated:0, loss_labels [0.0571887]\n",
      "RM:8.069, LSTAT:4.21, EXPENSIVE:1, Predicated:1, loss_labels [0.89193724]\n",
      "RM:7.155, LSTAT:4.82, EXPENSIVE:1, Predicated:1, loss_labels [0.81784923]\n",
      "RM:6.319, LSTAT:11.1, EXPENSIVE:1, Predicated:0, loss_labels [0.27510509]\n",
      "RM:3.863, LSTAT:13.33, EXPENSIVE:0, Predicated:0, loss_labels [0.0571887]\n",
      "RM:6.251, LSTAT:14.19, EXPENSIVE:0, Predicated:0, loss_labels [0.1158335]\n",
      "RM:5.277, LSTAT:30.81, EXPENSIVE:0, Predicated:0, loss_labels [0.00032782]\n",
      "RM:6.208, LSTAT:15.17, EXPENSIVE:0, Predicated:0, loss_labels [0.08476382]\n",
      "RM:6.556, LSTAT:4.56, EXPENSIVE:1, Predicated:1, loss_labels [0.78976407]\n",
      "RM:6.153, LSTAT:13.15, EXPENSIVE:1, Predicated:0, loss_labels [0.15083698]\n",
      "RM:5.813, LSTAT:19.88, EXPENSIVE:0, Predicated:0, loss_labels [0.0158346]\n",
      "RM:5.531, LSTAT:27.38, EXPENSIVE:0, Predicated:0, loss_labels [0.00115443]\n",
      "RM:5.837, LSTAT:15.69, EXPENSIVE:0, Predicated:0, loss_labels [0.06194546]\n",
      "RM:7.875, LSTAT:2.97, EXPENSIVE:1, Predicated:1, loss_labels [0.91979005]\n",
      "RM:6.193, LSTAT:15.17, EXPENSIVE:0, Predicated:0, loss_labels [0.08424984]\n",
      "RM:6.794, LSTAT:6.48, EXPENSIVE:0, Predicated:1, loss_labels [0.68713101]\n",
      "RM:6.495, LSTAT:8.67, EXPENSIVE:1, Predicated:0, loss_labels [0.48046761]\n",
      "RM:6.8, LSTAT:5.03, EXPENSIVE:1, Predicated:1, loss_labels [0.78149055]\n",
      "RM:6.377, LSTAT:20.45, EXPENSIVE:0, Predicated:0, loss_labels [0.01678333]\n",
      "RM:5.896, LSTAT:24.39, EXPENSIVE:0, Predicated:0, loss_labels [0.00367955]\n",
      "RM:6.172, LSTAT:19.15, EXPENSIVE:1, Predicated:0, loss_labels [0.02351242]\n",
      "RM:8.266, LSTAT:4.14, EXPENSIVE:1, Predicated:1, loss_labels [0.90215032]\n",
      "RM:6.545, LSTAT:21.08, EXPENSIVE:0, Predicated:0, loss_labels [0.01467611]\n",
      "RM:6.249, LSTAT:10.59, EXPENSIVE:0, Predicated:0, loss_labels [0.30379327]\n",
      "RM:4.906, LSTAT:34.77, EXPENSIVE:0, Predicated:0, loss_labels [7.39894801e-05]\n",
      "RM:7.416, LSTAT:6.19, EXPENSIVE:1, Predicated:1, loss_labels [0.76119151]\n",
      "RM:6.874, LSTAT:4.61, EXPENSIVE:1, Predicated:1, loss_labels [0.80963259]\n",
      "RM:5.875, LSTAT:8.88, EXPENSIVE:1, Predicated:0, loss_labels [0.39579698]\n",
      "RM:6.781, LSTAT:7.67, EXPENSIVE:1, Predicated:1, loss_labels [0.59458873]\n",
      "RM:4.97, LSTAT:3.26, EXPENSIVE:1, Predicated:1, loss_labels [0.74189882]\n",
      "RM:6.405, LSTAT:19.37, EXPENSIVE:0, Predicated:0, loss_labels [0.02420204]\n",
      "RM:7.014, LSTAT:14.79, EXPENSIVE:1, Predicated:0, loss_labels [0.13064883]\n",
      "RM:5.627, LSTAT:22.88, EXPENSIVE:0, Predicated:0, loss_labels [0.00540304]\n",
      "RM:5.012, LSTAT:12.12, EXPENSIVE:0, Predicated:0, loss_labels [0.13136915]\n",
      "RM:5.536, LSTAT:23.6, EXPENSIVE:0, Predicated:0, loss_labels [0.00408437]\n",
      "RM:5.304, LSTAT:26.64, EXPENSIVE:0, Predicated:0, loss_labels [0.00133695]\n",
      "RM:8.398, LSTAT:5.91, EXPENSIVE:1, Predicated:1, loss_labels [0.84393556]\n",
      "RM:6.739, LSTAT:4.69, EXPENSIVE:1, Predicated:1, loss_labels [0.79593437]\n",
      "RM:6.122, LSTAT:5.98, EXPENSIVE:0, Predicated:1, loss_labels [0.65843792]\n",
      "RM:6.169, LSTAT:5.81, EXPENSIVE:1, Predicated:1, loss_labels [0.67568607]\n",
      "RM:6.461, LSTAT:18.05, EXPENSIVE:0, Predicated:0, loss_labels [0.03803319]\n",
      "RM:6.593, LSTAT:9.67, EXPENSIVE:0, Predicated:0, loss_labels [0.40872692]\n",
      "RM:5.889, LSTAT:15.71, EXPENSIVE:0, Predicated:0, loss_labels [0.06290187]\n",
      "RM:7.274, LSTAT:6.62, EXPENSIVE:1, Predicated:1, loss_labels [0.72161968]\n",
      "RM:6.728, LSTAT:18.71, EXPENSIVE:0, Predicated:0, loss_labels [0.03445587]\n",
      "RM:5.898, LSTAT:12.67, EXPENSIVE:0, Predicated:0, loss_labels [0.15703605]\n",
      "RM:6.75, LSTAT:7.74, EXPENSIVE:1, Predicated:1, loss_labels [0.58560484]\n",
      "RM:6.484, LSTAT:18.68, EXPENSIVE:0, Predicated:0, loss_labels [0.03133911]\n",
      "RM:6.63, LSTAT:6.53, EXPENSIVE:1, Predicated:1, loss_labels [0.66760675]\n",
      "RM:6.23, LSTAT:12.93, EXPENSIVE:0, Predicated:0, loss_labels [0.16515451]\n",
      "RM:4.88, LSTAT:30.62, EXPENSIVE:0, Predicated:0, loss_labels [0.00029301]\n",
      "RM:5.891, LSTAT:10.87, EXPENSIVE:0, Predicated:0, loss_labels [0.25322036]\n",
      "RM:4.519, LSTAT:36.98, EXPENSIVE:0, Predicated:0, loss_labels [2.97667606e-05]\n",
      "RM:6.086, LSTAT:10.88, EXPENSIVE:1, Predicated:0, loss_labels [0.26923879]\n",
      "RM:6.957, LSTAT:3.53, EXPENSIVE:1, Predicated:1, loss_labels [0.86361076]\n",
      "RM:6.411, LSTAT:15.02, EXPENSIVE:0, Predicated:0, loss_labels [0.09628221]\n",
      "RM:8.259, LSTAT:3.54, EXPENSIVE:1, Predicated:1, loss_labels [0.91825932]\n",
      "RM:5.961, LSTAT:9.88, EXPENSIVE:0, Predicated:0, loss_labels [0.3275284]\n",
      "RM:6.642, LSTAT:9.69, EXPENSIVE:1, Predicated:0, loss_labels [0.41236003]\n",
      "RM:6.326, LSTAT:10.97, EXPENSIVE:1, Predicated:0, loss_labels [0.28449099]\n",
      "RM:5.786, LSTAT:14.15, EXPENSIVE:0, Predicated:0, loss_labels [0.09752219]\n",
      "RM:6.152, LSTAT:26.45, EXPENSIVE:0, Predicated:0, loss_labels [0.00207256]\n",
      "RM:6.635, LSTAT:5.99, EXPENSIVE:1, Predicated:1, loss_labels [0.70686508]\n",
      "RM:6.047, LSTAT:17.28, EXPENSIVE:0, Predicated:0, loss_labels [0.040842]\n",
      "RM:6.545, LSTAT:21.08, EXPENSIVE:0, Predicated:0, loss_labels [0.01467611]\n",
      "RM:6.739, LSTAT:4.69, EXPENSIVE:1, Predicated:1, loss_labels [0.79593437]\n",
      "RM:7.645, LSTAT:3.01, EXPENSIVE:1, Predicated:1, loss_labels [0.91086567]\n",
      "RM:6.957, LSTAT:3.53, EXPENSIVE:1, Predicated:1, loss_labels [0.86361076]\n",
      "RM:6.655, LSTAT:17.73, EXPENSIVE:0, Predicated:0, loss_labels [0.04575725]\n",
      "RM:7.079, LSTAT:5.7, EXPENSIVE:1, Predicated:1, loss_labels [0.76384061]\n",
      "RM:6.454, LSTAT:14.59, EXPENSIVE:0, Predicated:0, loss_labels [0.11141502]\n",
      "RM:6.333, LSTAT:7.34, EXPENSIVE:0, Predicated:1, loss_labels [0.57320018]\n",
      "RM:7.358, LSTAT:4.73, EXPENSIVE:1, Predicated:1, loss_labels [0.83505082]\n",
      "RM:7.416, LSTAT:6.19, EXPENSIVE:1, Predicated:1, loss_labels [0.76119151]\n",
      "RM:7.203, LSTAT:9.59, EXPENSIVE:1, Predicated:0, loss_labels [0.48193266]\n",
      "RM:5.627, LSTAT:22.88, EXPENSIVE:0, Predicated:0, loss_labels [0.00540304]\n",
      "RM:7.041, LSTAT:4.74, EXPENSIVE:1, Predicated:1, loss_labels [0.81428683]\n",
      "RM:5.569, LSTAT:15.1, EXPENSIVE:0, Predicated:0, loss_labels [0.06667536]\n"
     ]
    }
   ],
   "source": [
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5\n",
    "\n",
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], expensive[i]\n",
    "    predicate = model_r(np.array([x1, x2]), w_r, b_r)\n",
    "    loss_labels.append(predicate)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM:{}, LSTAT:{}, EXPENSIVE:{}, Predicated:{}, loss_labels'.format(x1, x2, y, predicate_label), predicate)\n",
    "\n",
    "    true_labels.append(y)\n",
    "    predicated_labels.append(predicate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ytrues, yhats):\n",
    "    return sum(1 for yt, y1 in zip(ytrues, yhats) if yt == y1) / len(ytrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(ytrues, yhats):\n",
    "    # What is the correct percentage of predictions where the label is 1\n",
    "\n",
    "    positives_pred = [y for y in yhats if y == 1]\n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and y == 1) / len(positives_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ytrues, yhats):\n",
    "    \n",
    "    true_positive = [y for y in ytrues if y == 1]     \n",
    "    return sum(1 for yt, y in zip(ytrues, yhats) if yt == y and yt == 1) / len(true_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441860465116279"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(true_labels, predicated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [0] * 90 + [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * 100\n",
    "b = [1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprecision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeople\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mprecision\u001b[0;34m(ytrues, yhats)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision\u001b[39m(ytrues, yhats):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# What is the correct percentage of predictions where the label is 1\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     positives_pred \u001b[38;5;241m=\u001b[39m [y \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m yhats \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mytrues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myhats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpositives_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "precision(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(people, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = [true_labels, predicated_labels, loss_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston_labels', 'wb') as f:\n",
    "    pickle.dump(boston_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels), len(predicated_labels), len(loss_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
