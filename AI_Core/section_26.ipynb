{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 26, Dufferent Optimizer Optimization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=(10000, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = torch.from_numpy(np.random.uniform(0, 5, size=(10000, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(in_features=8, out_features=1)\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "linear2 = torch.nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear, sigmoid, linear2).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(model(train_x).shape)\n",
    "print(ytrue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.3769, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3729, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3526, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.3162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2638, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.2317, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.1958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.1560, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.1124, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0650, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(9.0140, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9594, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.9011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.8395, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7744, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.7059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.6342, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.5594, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.4815, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.4005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.3167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.2301, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.1408, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(8.0490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.9546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.8579, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.7589, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.6577, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.5546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.4495, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.3426, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.2341, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.1240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(7.0125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.8996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.7856, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.6706, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.5546, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.4378, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.3204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.2024, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.0840, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.9653, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.8464, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.7275, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.6087, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.4901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.3718, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2540, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.1368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.0203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.9046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.7898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.6762, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5636, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4524, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3426, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2343, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.1277, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9196, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8184, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6223, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5275, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4351, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3450, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2575, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1726, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0903, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.0108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.9341, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8603, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7895, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7217, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.6570, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5955, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.5372, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.4306, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.3376, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2962, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2584, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.2241, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1664, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1429, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1070, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0808, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0795, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0819, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0879, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# yhat = model(train_x)\n",
    "# loss = loss_fn(yhat, ytrue)\n",
    "# print(loss)\n",
    "\n",
    "optimer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "for e in range(100):\n",
    "    yhat = model(train_x)\n",
    "    loss = loss_fn(yhat, ytrue)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
