# 4. Introduction to Mathematics - Fundamentals of Linear Algebra (Matrices)

**This article is section 4 of “[Hivan’s AI Compendium](https://medium.com/@hivan/list/hivans-ai-compendium-7ceb8b93d1a8) – Math Edition”**

![茶桁的AI秘籍Math_04](https://cdn.jsdelivr.net/gh/hivandu/notes/img/202408021736345.png)

Hi, everyone. I’m Hivan.

In the last class, we reviewed the concepts related to functions and derivatives. The calculus part isn’t over yet; there are still many details to cover. But for now, we’ll leave it at this for the basics.

In this class, we will review the basics of linear algebra.

## Matrices

In linear algebra, we primarily discuss matrices in the basics course.

You’ve probably heard of matrices before. We often talk about operations on matrices, Cramer's rule, the Jacobian matrix, and so on. But why do we need matrices?

Let’s look at this formula; this is what a matrix looks like:

$$
\begin{align*}
\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \vdots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix}
\end{align*}
$$

Now, let me introduce you to matrices. A matrix is essentially an arrangement of quantities arranged in rows and columns. For instance, in the formula above, each number has a subscript. The first number in the subscript indicates the row, and the second number indicates the column.

For example, in the first row, $a_{11}$ to $a_{1n}$, $a_{1n}$ represents the number in the 1st row and the nth column. Similarly, $a_{m1}$ is in the mth row and 1st column. That’s how we represent matrices.

There is a problem from an ancient mathematical text, *Sunzi’s Mathematical Classic*:

> Now there are chickens and rabbits in the same cage. There are 35 heads in total and 94 feet. How many chickens and how many rabbits are there? — *Sunzi’s Mathematical Classic*

## Chicken and Rabbit in the Same Cage

This is the famous problem of chickens and rabbits in a cage. We have 35 animals in total and 94 feet. How many chickens and rabbits are there? I’m sure many of you have encountered this problem before. Let’s use a conventional method to solve it:

$$
\begin{align*}
Solution: & \text{Let there be } x \text{ chickens and } y \text{ rabbits in the cage.} \\
& \begin{split}
& \begin{cases}
x+y = 35 & ...(1) \\
2x+4y = 94 & ...(2)
\end{cases} 
\end{split} \\
(2)-(1)\times2 \text{ gives:} \\
& \begin{split}
\begin{cases}
x+y = 35 & ...(3) \\
2y = 24  & ...(4)
\end{cases}
\end{split} \\
(4)\div2 \text{ gives:} \\
& \begin{split}
\begin{cases}
x+y = 35 & ...(5) \\
y = 12 & ...(6)
\end{cases}
\end{split} \\
(5)-(6) \text{ gives:} \\
& \begin{split}
\begin{cases}
x = 23 & ...(7) \\
y = 12 & ...(8)
\end{cases}
\end{split}
\end{align*}
$$

First, we assume there are $x$ chickens and $y$ rabbits in the cage. We then set up a system of linear equations:

First $x+y = 35$, representing the total number of animals, and $2x+4y = 94$, representing the total number of feet. By following the steps shown, we subtract equation (1) multiplied by 2 from equation (2), then solve equation (4) to get $y$. Finally, we substitute $y$ into equation (5) to find $x$. Thus, the final answer is 23 chickens and 12 rabbits.

## System of Linear Equations

This is quite standard, right? But let me ask you a question: What causes the differences between linear equations in a system, ultimately determining uniqueness?

- The number of unknowns?
- The number of equations?
- The number and values of coefficients?
- The symbols representing unknowns?

$$
\begin{align*}
\begin{cases}
a_1x_1+b_1x_2+c_1x_3+d_1x_4 = e_1 \\
a_2x_1+b_2x_2+c_2x_3+d_2x_4 = e_2 \\
a_3x_1+b_3x_2+c_3x_3+d_3x_4 = e_3 \\
a_4x_1+b_4x_2+c_4x_3+d_4x_4 = e_4 
\end{cases}
\end{align*}
$$

In the above system, if I replace $x$ with $y$, does it indicate a different system?

The correct answer is: the number and values of coefficients. Different coefficients correspond to different linear systems. For beginners, it might seem important what symbols are used for unknowns, but it really doesn’t matter whether you use $x$, $y$, $z$, $t$, $h$, or even characters from other languages.

So, matrices are derived as an abstraction of linear equations systems. We simply extract and arrange the coefficients to form a matrix:

$$
\begin{align*}
\begin{cases}
a_1x_1+b_1x_2+c_1x_3+d_1x_4 = e_1 \\
a_2x_1+b_2x_2+c_2x_3+d_2x_4 = e_2 \\
a_3x_1+b_3x_2+c_3x_3+d_3x_4 = e_3 \\
a_4x_1+b_4x_2+c_4x_3+d_4x_4 = e_4 
\end{cases}
\quad =>
\begin{bmatrix}
a_{1} & b_{1} & c_{1} & d_{1} & e_{1} \\
a_{2} & b_{2} & c_{2} & d_{2} & e_{2} \\
a_{3} & b_{3} & c_{3} & d_{3} & e_{3} \\
a_{4} & b_{4} & c_{4} & d_{4} & e_{4} \\
\end{bmatrix}
\end{align*}
$$

## Matrix Operations

Matrices have their own set of rules for operations, which are quite simple. Let’s look at matrix addition and subtraction:

$$
\begin{align*}
& \begin{split}  \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix} + \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix} = \begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\ a_{21}+b_{21} & a_{22}+b_{22} \end{bmatrix} \end{split} \\ \\
& \begin{split} \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix} - \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix} = \begin{bmatrix} a_{11}-b_{11} & a_{12}-b_{12} \\ a_{21}-b_{21} & a_{22}-b_{22} \end{bmatrix} \end{split}
\end{align*}
$$

First, the matrices must be of the same size. If the first matrix is $2 \times 2$, the second matrix must also be $2 \times 2$. If one matrix is $2 \times 2$ and the other is $3 \times 2$, they cannot be added or subtracted mathematically. So, corresponding elements are added or subtracted accordingly.

Scalar multiplication of a matrix means multiplying each element of the matrix by a scalar. Does this sound familiar? When learning Pandas, DataFrame operations have a similar characteristic. The result is:

$$
\begin{align*}
\begin{split} C \times \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix} =  \begin{bmatrix} Ca_{11} & Ca_{12} \\ Ca_{21} & Ca_{22} \end{bmatrix} \end{split}
\end{align*}
$$

Focus on matrix-vector multiplication. In neural networks, forward propagation involves multiplying the results from the previous layer (often in the form of vectors or matrices) by weight and bias matrices (or vectors) in the current layer. This is similar to the equation below:

**Matrix Vector Multiplication** -- The number of columns in the first matrix must equal the number of rows in the second matrix:

$$
\begin{align*}
& \begin{split} \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix} \times \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix} = \begin{bmatrix} a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\ a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22} \\ \end{bmatrix} \end{split}
\end{align*}
$$

So the mathematical principle corresponding to neural networks is very simple. Basically, if you know matrix-vector multiplication, you can understand how to provide a vector to a neural network, and then step by step, through layers, ultimately obtain an output value.

What are the rules for matrix-vector multiplication? For example, in the $2\times2$ matrix above, there is a prerequisite: the number of columns in the first matrix must be the same as the number of rows in the second matrix. In other words, if the first matrix has a certain number of columns, the second matrix must have the same number of rows. Why is this the case? We will understand this by looking at the calculation process.

First, when multiplying these two matrices, the result will also be a $2\times2$ matrix. The value in the top-left corner of the result matrix is obtained by multiplying the first row of the first matrix by the first column of the second matrix. That is, the first row and the first column are multiplied together.

In the result matrix, the bottom-left value is the result of multiplying the second row of the first matrix by the first column of the second matrix. This is simple to remember: for the term $a_{21}b_{11} + a_{22}b_{21}$, it is indeed in the second row, first column of the result matrix, right? Since it is in the second row, first column, we know that we take the second row from the first matrix and the first column from the second matrix, corresponding to each other.

Similarly, for $a_{11}b_{12} + a_{12}b_{22}$, it is in the first row, second column, so it needs to be calculated by multiplying the first row of the first matrix and the second column of the second matrix. This is actually very simple, so don’t think that the math in AI is very complex or profound. Any complex thing is based on very simple principles, and the complexity comes from different combinations of these basic principles.

Just like in the previous example, we said that no matter how complex a chip or circuit is, it is composed of AND, NOT, and OR gates. It’s just that the combination might be a bit more complex.

Let's look at an example: how do we calculate the result of multiplying the following two matrices according to the definition we just mentioned?

$$
\begin{align*}
\text{Example:} & \text{Calculate the result of multiplying the following two matrices:} \\
& \begin{split} \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \times \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} = ? \end{split}
\end{align*}
$$

Let's directly see the result:

$$
\begin{align*}
\begin{split} \text{Solution:} \begin{bmatrix} 1 & 2 \\ 3 & 4  \end{bmatrix} \times \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} & = \begin{bmatrix} 1\times5 + 2\times7 & 1\times6 + 2\times8 \\ 3\times5 + 4\times7 & 3\times6 + 4\times8 \end{bmatrix} \\ \\ & = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix} \end{split}
\end{align*}
$$

First, let's look at multiplying these two matrices. We first check if the number of columns in the first matrix matches the number of rows in the second matrix. With two columns and two rows, the operation can be performed. The elements of the first matrix are taken by rows, and those of the second matrix by columns; 1, 2 and 5, 7 correspondingly multiply.

Other positions also correspond to multiplication. For example, the element in the bottom-right corner is obtained by multiplying the second row by the second column, resulting in $3\times6 + 4\times8 = 50$. In neural networks, the weight is multiplied by the output of the previous layer, and then the bias vector is added. This is basically the same thing. It’s simple and not complex. But if you don’t understand, you won’t know how neural networks perform forward propagation in AI.

Let's look at another example:

$$
\begin{align*}
\begin{split} \begin{bmatrix} 10 & 11 \\ 12 & 13 \end{bmatrix} \begin{bmatrix} 4 \\ 5 \end{bmatrix} = ?
\end{split}
\end{align*}
$$

This example is similar, just a bit more special. Here, it is not a $2\times2$ matrix but a $2\times1$ matrix. The calculation result is as follows:

$$
\begin{align*}
\begin{split} \text{Solution:} \begin{bmatrix} 10 & 11 \\ 12 & 13 \end{bmatrix} \begin{bmatrix} 4 \\ 5 \end{bmatrix} & =  \begin{bmatrix} 10 \times 4 + 11 \times 5 \\ 12 \times 4 + 13 \times 5 \end{bmatrix} \\ \\ & = \begin{bmatrix} 95 \\ 113 \end{bmatrix} \end{split}
\end{align*}
$$

The second matrix has only one column. If the first matrix is $m \times n$ and the second matrix is $n \times k$, then the resulting matrix is $m \times k$. In other words, (this is a key point) **the size of the first matrix $M_1$: $m\times n$, the size of the second matrix $M_2$: $n\times k$, the resulting matrix $M_{res}$ from multiplying $M_1$ and $M_2$ is: $m\times k$.**

This explains why the number of columns in the first matrix must be equal to the number of rows in the second matrix. If they are not equal, the multiplication cannot be performed.

In future lessons, we will continue to focus on this detail. This lesson is just to familiarize you with the concept and understand how it works.

What can matrices do? Here, let’s use a geometric example to explain. I have a matrix and a vector:

$$
\begin{align*}
\begin{split} \begin{bmatrix} \cos90^\circ & -\sin90^\circ \\ \sin90^\circ & \cos90^\circ \end{bmatrix} \begin{bmatrix} 2 \\ -2 \end{bmatrix} \end{split}
\end{align*}
$$

Then we place this vector in a Cartesian coordinate system:

![image-20230825222020860](https://raw.githubusercontent.com/hivandu/notes/main/img/20230825222021.png)

This vector can be represented as an arrow in the plane coordinate system. What result do we get when we perform matrix-vector multiplication? Let's calculate it:

$$
\begin{align*}
\begin{split} & \begin{bmatrix} \cos90^\circ & -\sin90^\circ \\ \sin90^\circ & \cos90^\circ \end{bmatrix} \begin{bmatrix} 2 \\ -2 \end{bmatrix} \\ & =  \begin{bmatrix} 2\cos90^\circ + 2\sin90^\circ \\ 2\sin90^\circ - 2\cos90^\circ \end{bmatrix} \\ & =  \begin{bmatrix} 2 \\ 2 \end{bmatrix} \end{split}
\end{align*}
$$

Then place the resulting vector in the coordinate system:

![image-20230825225602701](https://raw.githubusercontent.com/hivandu/notes/main/img/20230825225602.png)

From a geometric perspective, this corresponds to a counterclockwise rotation of 90 degrees. Therefore, the geometric meaning of matrices in this example is a rotation transformation. We rotate a vector, and the 90 degrees in our matrix corresponds to the trigonometric value in the matrix.

Apart from rotation, matrices can also be used for stretching. We'll encounter examples of stretching in future lessons, but for now, this example helps us understand the significance of matrices.

## Matrix Transposition

The transpose of a matrix involves flipping the matrix along its diagonal axis or, in other words, swapping rows with columns. We discussed row-to-column transformation in our Python course; if you've forgotten, you can review those sections.

For example, the matrix 

$$
\begin{align*}
\begin{split}
\begin{bmatrix}
1 & 2 & 3 & 4 \\
5 & 6 & 7 & 8 \\
9 & a & b & c
\end{bmatrix} ^T
=>
\begin{bmatrix}
1 & 5 & 9 \\
2 & 6 & a \\
3 & 7 & b \\
4 & 8 & c
\end{bmatrix}
\end{split}
\end{align*}
$$

transposed becomes 

$$
\begin{bmatrix}
1 & 5 & 9 \\
2 & 6 & a \\
3 & 7 & b \\
4 & 8 & c
\end{bmatrix}
$$

This concept is quite easy to understand.

## Matrix Inversion

The inverse of a matrix is somewhat analogous to division in arithmetic. Multiplying a matrix by its inverse yields the identity matrix, which has 1s on the diagonal and 0s elsewhere:

$$
\begin{align*}
\begin{split}
A^{-1} \text{ satisfies: } AA^{-1} = I, \text{ where } I =
\begin{bmatrix}
1 & \cdots & 0 \\
\vdots & \ddots & \vdots \\
0 & \cdots & 1
\end{bmatrix}.
\end{split}
\end{align*}
$$

Solving systems of equations often involves finding the inverse of the coefficient matrix. The concept of the matrix inverse is extensively covered in higher algebra, but for now, just be aware of its general purpose. We will discuss it in more detail later.

On a side note, while China and the United States are leading in AI research, most literature in this field is in English. Therefore, I suggest improving your English skills. You may need to understand algorithms and implementations from AI papers, which are often written in English.

From my experience, specialized fields are often less challenging to read in English. Unlike GRE reading comprehension, which can be quite difficult, reading specialized materials in fields like AI can be simpler, as they use more specific terminology rather than complex grammatical structures. Mastering specialized terms is usually enough; basic high school English is often sufficient.

This should not be an obstacle, so I recommend starting to enhance your English reading skills now and gradually expanding into other areas.

That concludes this lesson. In the next class, we will look into "Probability & Statistics."

Friends who need it, please click to subscribe: "[Hivan's AI Compendium](https://medium.com/@hivan/list/hivans-ai-compendium-7ceb8b93d1a8) "

https://medium.com/@hivan/list/hivans-ai-compendium-7ceb8b93d1a8